{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a486c4-7407-4d13-b1ec-f969d3a5ac81",
   "metadata": {},
   "source": [
    "<img src=\"./data/img/ranking_wise.jpeg\" />\n",
    "\n",
    "pointwise常用算法\n",
    "--\n",
    "\n",
    "Classification\n",
    "+ Discriminative model for IR (SIGIR 2004)\n",
    "+ McRank (NIPS 2007)\n",
    "\n",
    "Regression\n",
    "+ Least Square Retrieval Function (TOIS 1989)\n",
    "+ Regression Tree for Ordinal Class Prediction (Fundamenta Informaticae, 2000)\n",
    " + Subset Ranking using Regression (COLT 2006)\n",
    " \n",
    "Ordinal Classification\n",
    "+ Ranking with Large Margin Principles (NIPS 2002)\n",
    "+ Constraint Ordinal Regression (ICML 2005)\n",
    "\n",
    "### 特点\n",
    "Pointwise 类方法，其 L2R 框架具有以下特征：\n",
    "\n",
    "+ 输入空间中样本是单个 doc（和对应 query）构成的特征向量；\n",
    "+ 输出空间中样本是单个 doc（和对应 query）的相关度；\n",
    "+ 假设空间中样本是打分函数；\n",
    "+ 损失函数评估单个 doc 的预测得分和真实得分之间差异。\n",
    "\n",
    "这里讨论下，关于人工标注标签怎么转换到 pointwise 类方法的输出空间：\n",
    "\n",
    "+ 如果标注直接是相关度 s_j，则 doc x_j 的真实标签定义为 y_j=s_j\n",
    "+ 如果标注是 pairwise preference s_{u,v}，则 doc x_j 的真实标签可以利用该 doc 击败了其他 docs 的频次\n",
    "+ 如果标注是整体排序 π，则 doc x_j 的真实标签可以利用映射函数，如将 doc 的排序位置序号当作真实标签\n",
    "\n",
    "### 根据使用的 ML 方法不同，pointwise 类可以进一步分成三类：基于回归的算法、基于分类的算法，基于有序回归的算法。\n",
    "（1）基于回归的算法    \n",
    "　　　此时，输出空间包含的是实值相关度得分。采用 ML 中传统的回归方法即可。    \n",
    "（2）基于分类的算法   \n",
    "     此时，输出空间包含的是无序类别。对于二分类，SVM、LR 等均可；对于多分类，提升树等均可。   \n",
    "（3）基于有序回归的算法   \n",
    " 此时，输出空间包含的是有序类别。通常是找到一个打分函数，然后用一系列阈值对得分进行分割，得到有序类别。采用 PRanking、基于 margin 的方法都可以。   \n",
    "\n",
    "### 缺陷  \n",
    "　回顾概述中提到的评估指标应该基于 query 和 position，\n",
    "+ ranking 追求的是排序结果，并不要求精确打分，只要有相对打分即可。\n",
    "+ pointwise 类方法并没有考虑同一个 query 对应的 docs 间的内部依赖性。一方面，导致输入空间内的样本不是 IID 的，违反了 ML 的基本假设，另一方面，没有充分利用这种样本间的结构性。其次，当不同 query 对应不同数量的 docs 时，整体 loss 将会被对应 docs 数量大的 query 组所支配，前面说过应该每组 query 都是等价的。\n",
    "+ 损失函数也没有 model 到预测排序中的位置信息。因此，损失函数可能无意的过多强调那些不重要的 docs，即那些排序在后面对用户体验影响小的 doc。\n",
    "\n",
    "### 改进\n",
    "　如在 loss 中引入基于 query 的正则化因子的 RankCosine 方法。\n",
    "\n",
    "Pairwise常用算法:\n",
    "--\n",
    "\n",
    "+ Learning to Retrieve Information (SCC 1995)\n",
    "+ Learning to Order Things (NIPS 1998)\n",
    "+ Ranking SVM (ICANN 1999)\n",
    "+ RankBoost (JMLR 2003)\n",
    "+ LDM (SIGIR 2005)\n",
    "+ RankNet (ICML 2005)\n",
    "+ Frank (SIGIR 2007)\n",
    "+ MHR(SIGIR 2007)\n",
    "+ GBRank (SIGIR 2007)\n",
    "+ QBRank (NIPS 2007)\n",
    "+ MPRank (ICML 2007)\n",
    "+ IRSVM (SIGIR 2006)\n",
    "+ LambdaMART (inf.retr 2010) 也可以做pair-wise\n",
    "\n",
    "<img src=\"data/img/ranknet.jpeg\"/>\n",
    "\n",
    "$x_i => s_i = f(x_i)$ \\\n",
    "$U_i相关性比U_j好的概率 P_{i,j} = P(U_i > U_j)= \\frac {1}{1 + e^{-\\sigma(s_i - sj)}}$\\\n",
    "$交叉熵损失函数 C_{i,j} = -\\overline{P}_{i,j} \\log P_{i,j} - (1 - \\overline{P}_{i,j}) \\log (1 - P_{i,j})$\\\n",
    "$\\overline{P}_{i,j} = \\frac{1}{2}(1 + S_{i,j}),  S_{i,j} = {+1, 0}$\\\n",
    "$\\lambda _{i,j} = \\frac {\\partial C}{\\partial s_i} = \\frac{1}{2}(1 - S_{i,j}) - \\frac {1}{1 + e^{\\sigma(s_i - sj)}}$\n",
    "\n",
    "\n",
    "### 特点\n",
    "　　Pairwise 类方法，其 L2R 框架具有以下特征：\n",
    "\n",
    "+ 输入空间中样本是（同一 query 对应的）两个 doc（和对应 query）构成的两个特征向量；\n",
    "+ 输出空间中样本是 pairwise preference；\n",
    "+ 假设空间中样本是二变量函数；\n",
    "+ 损失函数评估 doc pair 的预测 preference 和真实 preference 之间差异。\n",
    "\n",
    "  这里讨论下，关于人工标注标签怎么转换到 pairwise 类方法的输出空间：\n",
    "\n",
    "+ $如果标注直接是相关度 s_j，则 \\text{doc pair }(x_u,x_v) 的真实标签定义为 y_{u,v}=2*I_{s_u>s_v}-1 $\n",
    "+ $如果标注是 \\text{pairwise preference }s_{u,v}，则 doc pair (x_u,x_v) 的真实标签定义为y_{u,v}=s_{u,v}$\n",
    "+ $如果标注是整体排序 π，则 \\text{doc pair }(x_u,x_v) 的真实标签定义为y_{u,v}=2*I_{π_u,π_v}-1$\n",
    "\n",
    "### 基于二分类的算法　　\n",
    "　　Pairwise 类方法基本就是使用二分类算法即可。\n",
    "\n",
    "　　经典的算法有 基于 NN 的 SortNet，基于 NN 的 RankNet，基于 fidelity loss 的 FRank，基于 AdaBoost 的 RankBoost，基于 SVM 的 RankingSVM，基于提升树的 GBRank。\n",
    "\n",
    "### 缺陷  \n",
    "　　虽然 pairwise 类相较 pointwise 类 model 到一些 doc pair 间的相对顺序信息，但还是存在不少问题，回顾概述中提到的评估指标应该基于 query 和 position，如果人工标注给定的是第一种和第三种，即已包含多有序类别，那么转化成 pairwise preference 时必定会损失掉一些更细粒度的相关度标注信息。\n",
    "doc pair 的数量将是 doc 数量的二次，从而 pointwise 类方法就存在的 query 间 doc 数量的不平衡性将在 pairwise 类方法中进一步放大。\n",
    "+ pairwise 类方法相对 pointwise 类方法对噪声标注更敏感，即一个错误标注会引起多个 doc pair 标注错误。\n",
    "+ pairwise 类方法仅考虑了 doc pair 的相对位置，损失函数还是没有 model 到预测排序中的位置信息。\n",
    "+ pairwise 类方法也没有考虑同一个 query 对应的 doc pair 间的内部依赖性，即输入空间内的样本并不是 IID 的，违反了 ML 的基本假设，并且也没有充分利用这种样本间的结构性。\n",
    "\n",
    "### 改进\n",
    "　　　pairwise 类方法也有一些尝试，去一定程度解决上述缺陷，比如：\n",
    "\n",
    "+ Multiple hyperplane ranker，主要针对前述第一个缺陷\n",
    "+ magnitude-preserving ranking，主要针对前述第一个缺陷\n",
    "+ IRSVM，主要针对前述第二个缺陷\n",
    "+ 采用 Sigmoid 进行改进的 pairwise 方法，主要针对前述第三个缺陷\n",
    "+ P-norm push，主要针对前述第四个缺陷\n",
    "+ Ordered weighted average ranking，主要针对前述第四个缺陷\n",
    "+ LambdaRank，主要针对前述第四个缺陷\n",
    "+ Sparse ranker，主要针对前述第四个缺陷\n",
    "\n",
    "Listwise常用算法:\n",
    "--\n",
    "\n",
    "+ Measure-specific\n",
    "+ AdaRank (SIGIR 2007)\n",
    "+ SVM-MAP (SIGIR 2007)\n",
    "+ SoftRank (LR4IR 2007)\n",
    "+ RankGP (LR4IR 2007)\n",
    "+ LambdaRank (NIPS 2006)\n",
    "+ LambdaMART (inf.retr 2010)\n",
    "+ Non-measure specific\n",
    "+ ListNet (ICML 2007)\n",
    "+ ListMLE (ICML 2008)\n",
    "+ BoltzRank (ICML 2009)\n",
    "\n",
    "<img src=\"data/img/lambdarank.jpeg\" />\n",
    "\n",
    "$\\lambda _{i,j} = \\frac {\\partial C}{\\partial s_i} = \\frac {\\sigma}{1 + e^{\\sigma(s_i - sj)}} |\\Delta NDCG|$\n",
    "\n",
    "### 特点　　\n",
    "　　Listwise 类方法，其 L2R 框架具有以下特征：\n",
    "\n",
    "+ 输入空间中样本是（同一 query 对应的）所有 doc（与对应的 query）构成的多个特征向量（列表）；\n",
    "+ 输出空间中样本是这些 doc（和对应 query）的相关度排序列表或者排列；\n",
    "+ 假设空间中样本是多变量函数，对于 docs 得到其排列，实践中，通常是一个打分函数，根据打分函数对所有 docs 的打分进行排序得到 docs 相关度的排列；\n",
    "+ 损失函数分成两类，一类是直接和评价指标相关的，还有一类不是直接相关的。具体后面介绍。\n",
    "\n",
    "  这里讨论下，关于人工标注标签怎么转换到 listwise 类方法的输出空间：\n",
    "\n",
    "+ $如果标注直接是相关度 s_j，则 \\text{doc set} 的真实标签可以利用相关度 s_j 进行比较构造出排列$\n",
    "+ $如果标注是 \\text{pairwise preference } s_{u,v}，则 doc set 的真实标签也可以利用所有 s_{u,v} 进行比较构造出排列$\n",
    "+ 如果标注是整体排序 π，则 doc set 则可以直接得到真实标签\n",
    " \n",
    "\n",
    "### 根据损失函数构造方式的不同，listwise 类可以分成两类直接基于评价指标的算法，间接基于评价指标的算法。\n",
    "（1）直接基于评价指标的算法   \n",
    "  直接取优化 ranking 的评价指标，也算是 listwise 中最直观的方法。但这并不简单，因为前面说过评价指标都是离散不可微的，具体处理方式有这么几种：\n",
    "\n",
    "+ 优化基于评价指标的 ranking error 的连续可微的近似，这种方法就可以直接应用已有的优化方法，如SoftRank，ApproximateRank，SmoothRank\n",
    "+ 优化基于评价指标的 ranking error 的连续可微的上界，如 SVM-MAP，SVM-NDCG，PermuRank\n",
    "+ 使用可以优化非平滑目标函数的优化技术，如 AdaRank，RankGP\n",
    "\n",
    "  上述方法的优化目标都是直接和 ranking 的评价指标有关。现在来考虑一个概念，informativeness。通常认为一个更有信息量的指标，可以产生更有效的排序模型。而多层评价指标（NDCG）相较二元评价（AP）指标通常更富信息量。因此，有时虽然使用信息量更少的指标来评估模型，但仍然可以使用更富信息量的指标来作为 loss 进行模型训练。\n",
    "\n",
    "（2）非直接基于评价指标的算法\n",
    "　这里，不再使用和评价指标相关的 loss 来优化模型，而是设计能衡量模型输出与真实排列之间差异的 loss，如此获得的模型在评价指标上也能获得不错的性能。 \n",
    "　　经典的如 ，ListNet，ListMLE，StructRank，BoltzRank。\n",
    "\n",
    " \n",
    "\n",
    "### 缺陷  \n",
    "listwise 类相较 pointwise、pairwise 对 ranking 的 model 更自然，解决了 ranking 应该基于 query 和 position 问题。\n",
    "\n",
    "listwise 类存在的主要缺陷是：一些 ranking 算法需要基于排列来计算 loss，从而使得训练复杂度较高，如 ListNet和 BoltzRank。此外，位置信息并没有在 loss 中得到充分利用，可以考虑在 ListNet 和 ListMLE 的 loss 中引入位置折扣因子。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235d3757-a302-4133-9e8b-533746fa797b",
   "metadata": {},
   "source": [
    "L2R 评价指标主要有 NDCG、MAP、WTA、MRR \n",
    "![alt \"ltr\"](./data/img/ltr.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1af4a9f-a095-42bd-9e8e-a353fcbb524d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## NDCG\n",
    "全称为 Normalized Discounted Cumulative Gain，是一种综合考虑模型排序结果和真实序列之间的关系的一种指标，也是最常用的衡量排序结果的指标\n",
    "\n",
    "$NDCG@K = \\frac {DCG}{iDCG}$  \n",
    "分子为模型计算出的 DCG 值，分母则为理想情况下的 DCG 值，而 DCG 的计算公式如下：\n",
    "\n",
    "$DCG = \\sum_i^k \\frac{2^{r(i)} - 1}{\\log_2(i+1)}$\n",
    "\n",
    "$在 DCG 的表达式中，r(i)表示在模型给出的排序中，排名为 i 的元素的实际分数，这里通过 2^{r(i)-1} 运算放大了其分数的差异，log_2(i+1) 是每个元素的折价，由于排序靠前的元素被选取的概率更大，所以这里可以使得排名前面的元素影响权重更大。$\n",
    "\n",
    "## MAP\n",
    "\n",
    "MAP，全称为 Mean Average Precision，即平均准确率。\n",
    "\n",
    "考虑其在模型排序结果中的位置 P，统计该位置之前的文档集合的分类准确率，取所有这些准确率的平均值。\n",
    "\n",
    "$ MAP = \\frac{1}{P} \\sum_i^P \\frac{i}{rank\\_idx(i)}$   \n",
    "\n",
    "rank_idx(i) 表示第i个query正确结果的排序位置\n",
    "\n",
    "对于一个 Query，原本有 4 个相关结果，查询时将 4 个结果都查询出来了，其 rank 分别为 1, 2, 4, 7，则 MAP 为 (1/1 + 2/2 + 3/4 + 4/7)/4 = 0.83。对于另一个 Query，原本有 5 个相关结果，查询只有 3 个相关结果，其 rank 分别为 1, 3, 5，则 MAP 为 (1/1 + 2/3 + 3/5 + 0 + 0)/5 = 0.45。则 MAP = (0.83 + 0.45)/2 = 0.64。\n",
    "\n",
    "\n",
    "## MRR\n",
    "\n",
    "MRR，全称 Mean Reciprocal Rank，是把相关文档在结果中的排序倒数作为准确度，然后再取平均。\n",
    "\n",
    "$ MRR = \\frac{1}{N} \\sum_i^N \\frac{1}{rank\\_idx(i)}$    \n",
    "rank_idx(i) 表示第i个query正确结果的排序位置\n",
    "\n",
    "如对于第一个 Query，查询结果将正确结果排名 rank 为 3，则其 Reciprocal Rank 为 1/3，对于第二个 Query，查询结果将正确结果排名 rank 为 2，则其 Reciprocal Rank 为 1/2，对于第三个 Query，查询结果将正确结果排名 rank 为 1，则其 Reciprocal Rank 为 1，则 MRR = (1/3 + 1/2 + 1)/3 = 11/18 = 0.61。\n",
    "\n",
    "\n",
    "## WTA\n",
    "WTA，全称 Winners Take All，对于给定的查询 Query，如果模型返回的结果列表中，第一个文档是相关的，则 WTA =1， 否则为 0。\n",
    "\n",
    "如对于一个 Query，本来有 5 个相关结果，查询结果中如果第一个结果是相关的，那么 WTA = 1，如果第一个结果是不相关的，则 WTA = 0。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58353741-7e23-4688-bd7e-6be2ca74c4b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
