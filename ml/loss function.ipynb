{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27c48607-2046-4fde-8626-1e48a04b910b",
   "metadata": {},
   "source": [
    "# 回归任务\n",
    "\n",
    "<img src=\"./data/img/L1_L2_loss.png\" style=\"zoom:50%\"/>\n",
    "\n",
    "## L1范数损失 L1Loss\n",
    "在机器学习和深度学习中，L1范数损失通常用于正则化和稀疏性推动。通过最小化L1范数损失，可以鼓励模型产生稀疏的权重或特征选择，因为L1范数倾向于将一些权重或特征设置为零。\n",
    ">$ J = loss(y, \\hat y) = \\sum|y - \\hat y|$    \n",
    "> $ \\frac {\\partial J} {\\partial \\hat y} = N_1 - N_2,  N_2表示 y≥\\hat y的个数，N_1表示 y<\\hat y的个数 $   \n",
    "> torch.nn.L1Loss(reduction='mean')\n",
    "\n",
    "应用场景：回归任务，简单的模型，由于神经网络通常是解决复杂问题，所以很少使用。\n",
    "\n",
    "\n",
    "## 均方误差（L2 Loss)损失 MSELoss\n",
    "计算 output 和 target 之差的均方差。   \n",
    "MSE损失的优点是对较大的预测误差有较高的惩罚，因为差异的平方放大了较大的误差。同时，MSE损失在数学性质上也比较好，易于计算和求导。\n",
    ">$ J = loss(y, \\hat y) = \\frac {1}{n} \\sum \\frac {1}{2}(y - \\hat y)^2$    \n",
    ">$ \\frac {\\partial J} {\\partial \\hat y} =  \\frac {1}{n} \\sum (\\hat y - y)$  \n",
    ">torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "应用场景：回归任务，数值特征不大问，题维度不高\n",
    "\n",
    "## 平滑版L1损失 SmoothL1Loss\n",
    "当预测值和ground truth差别较小的时候（绝对值差小于1），其实使用的是L2 Loss；而当差别大的时候，是L1 Loss的平移。\n",
    ">torch.nn.SmoothL1Loss(reduction='mean')\n",
    "\n",
    "应用场景：回归任务, 特征中有较大的数值，适合大多数问题\n",
    "\n",
    "reduction-三个值，none: 不使用约简；mean:返回loss和的平均值；sum:返回loss的和。默认：mean。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcde016c-bc8a-47db-842e-1f8087c0e801",
   "metadata": {},
   "source": [
    "# 分类任务\n",
    "\n",
    "## 交叉熵损失 CrossEntropyLoss\n",
    "当训练有 C 个类别的分类问题时很有效. 可选参数 weight 必须是一个1维 Tensor, 权重将被分配给各个类别. 对于不平衡的训练集非常有效。\n",
    "在多分类任务中，经常采用 softmax 激活函数+交叉熵损失函数，因为交叉熵描述了两个概率分布的差异，然而神经网络输出的是向量，并不是概率分布的形式。所以需要 softmax激活函数将一个向量进行“归一化”成概率分布的形式，再采用交叉熵损失函数计算 loss。\n",
    ">$ J = loss(y, \\hat y) = - \\sum_c y_c\\log(\\hat y_c)$   \n",
    ">$ \\hat y_i = softmax(z_i) = \\frac {e^{z_i}}{\\sum_c e^{z_c}}$   \n",
    ">$ \\frac {\\partial J} {\\partial Z} = \\hat y - y$  \n",
    "torch.nn.CrossEntropyLoss(weight=None,ignore_index=-100, reduction='mean')   \n",
    "weight (Tensor, optional) – 自定义的每个类别的权重. 必须是一个长度为 C 的 Tensor   \n",
    "ignore_index (int, optional) – 设置一个目标值, 该目标值会被忽略, 从而不会影响到 输入的梯度。\n",
    "\n",
    "应用场景：多分类\n",
    "\n",
    "##  KL 散度（相对熵）损失 KLDivLoss\n",
    "计算 input 和 target 之间的 KL 散度。KL 散度可用于衡量不同的连续分布之间的距离, 在连续的输出分布的空间上(离散采样)上进行直接回归时 很有效.   \n",
    "KL散度通常用于无监督学习任务中，如聚类、降维和生成模型等。在这些任务中，我们没有相应的标签信息，因此无法使用交叉熵来评估模型的性能，所以需要一种方法来衡量模型预测的分布和真实分布之间的差异，这时就可以使用KL散度来衡量模型预测的分布和真实分布之间的差异。   \n",
    "需要注意的是，KL散度损失不具有对称性，即KLDivLoss(P, Q)与KLDivLoss(Q, P)的值可能不相等。因此，在实际应用中，我们通常将KL散度损失与交叉熵损失（CrossEntropyLoss）结合使用，以获得更好的效果。\n",
    "\n",
    ">$ J = loss(\\hat y, y) = \\sum_c y_c(-\\log\\hat y_c) - \\sum_c y_c(-\\log y_c) = \\sum_c y_c \\log(\\frac {y_c}{\\hat y})$     \n",
    ">$ \\hat y_i = softmax(z_i) = \\frac {e^{z_i}}{\\sum_c e^{z_c}}$    \n",
    ">$ - \\sum_c y_c(-\\log y_c)  常数， 所以  \\frac {\\partial J} {\\partial Z} = \\hat y - y$    \n",
    ">torch.nn.KLDivLoss(reduction='mean')\n",
    "\n",
    "应用场景：无监督学习，如聚类、降维和生成模型等\n",
    "\n",
    "## 二进制交叉熵损失 BCELoss\n",
    "BCE损失函数的优点是在二分类问题中比较直观且易于计算(多分类的特殊形式）。它对于模型预测接近真实标签的情况有较低的损失，同时对于模型预测明显错误的情况有较高的惩罚。\n",
    "> $ J = loss(\\hat y, y) = -(y * \\log \\hat y + (1-y)*\\log(1-\\hat y))$   \n",
    "> $ \\hat y_i = sigmoid(z_i) = \\sigma (z_i) = \\frac {e^{z_i}}{1 + e^{z_i}}$   \n",
    "> $ \\frac {\\partial J} {\\partial Z} = \\hat y - y$   \n",
    "> torch.nn.BCELoss(weight=None, reduction='mean')\n",
    "\n",
    "应用场景：二分类\n",
    "\n",
    "## BCEWithLogitsLoss\n",
    "BCEWithLogitsLoss损失函数把 Sigmoid 层集成到了 BCELoss 类中。   \n",
    "与BCELoss不同的是，BCEWithLogitsLoss直接在内部应用sigmoid函数，省去了手动应用sigmoid函数的步骤。\n",
    "\n",
    ">$ J = BCEWithLogitsLoss(y, \\hat y) = -[y \\log(\\sigma(\\hat y)) + (1 - y) \\log(1 - \\sigma(\\hat y))]$   \n",
    ">$ \\sigma(\\hat y) = sigmoid(\\hat y), $   \n",
    ">$ \\frac {\\partial J}{\\partial \\hat y} = \\sigma(\\hat y) - y$   \n",
    ">torch.nn.BCEWithLogitsLoss(weight=None, reduction='mean', pos_weight=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae396a4-7179-45b3-b2e4-e7489c4b53e3",
   "metadata": {},
   "source": [
    "# 度量学习(metric learning)\n",
    "\n",
    "ranking loss在很多不同的领域，任务和神经网络结构（比如siamese net或者Triplet net）中被广泛地应用。其广泛应用但缺乏对其命名标准化导致了其拥有很多其他别名，比如对比损失Contrastive loss，边缘损失Margin loss，铰链损失hinge loss和我们常见的三元组损失Triplet loss等。\n",
    "\n",
    "## MarginRankingLoss\n",
    "MarginRankingLoss（边际排序损失）是一种用于学习排序模型的损失函数，常用于训练具有排序目标的模型，例如排序任务、排序推荐系统等。\n",
    "\n",
    "MarginRankingLoss的目标是将正样本的预测得分（正例）与负样本的预测得分（负例）之间的差异最大化，同时保持一定的边际（margin）。这样可以促使模型在预测时更好地区分正负样本，从而提高排序性能。\n",
    "\n",
    "min-batch, $ MarginRankingLoss = max(0, -y * (\\hat y_p - \\hat y_n) + margin)其中，y为标签，取值为1或-1，表示正样本或负样本；\\hat y_p为正样本的预测得分；\\hat y_n为负样本的预测得分；margin为边际，是一个预先指定的超参数。$\n",
    "\n",
    "> \n",
    ">torch.nn.MarginRankingLoss(margin=0.0, reduction='mean')\n",
    "\n",
    "应用场景：孪生（Siamese）网络，GAN，排名任务，开源实现和实例非常少\n",
    "\n",
    "<img src=\"./data/img/ranking_loss.webp\" />\n",
    "\n",
    "## HingeEmbeddingLoss\r\n",
    "HingeEmbeddingLoss（铰链嵌入损失）是一种用于训练支持向量机（Support Vector Machine，SVM）模型的损失函数，常用于二分类任务。它的目标是鼓励模型将正负样本分开，并在一定程度上惩罚分类错误。266\n",
    "\n",
    "$ J = HingeEmbeddingLoss(y, \\hat y) = max(0, margin - y * \\hat y) ,y ∈\\{-1, 1\\}$  \n",
    "$\n",
    "J = HingeEmbeddingLoss(y, \\hat y)=\\begin{cases}\n",
    "max(0, margin - \\hat y) & y == 1 \\\\\n",
    "max(0, margin + \\hat y) & y == -1\n",
    "\\end{cases}\n",
    "$\n",
    "\n",
    "$ \n",
    "\\frac {\\partial J}{\\partial \\hat y} = \\begin{cases}\n",
    "1 & y == -1 \\text{ and } margin > -\\hat y \\\\\n",
    "0  & margin < y * \\hat y \\\\\n",
    "-1 & y == 1 \\text{ and } margin > \\hat y\n",
    "\\end{cases}\n",
    "$  \n",
    "HingeEmbeddingLoss 是一种损失函数，通常用于训练具有嵌入向量（embedding vectors）的模型，如Siamese网络，Triplet网络等，以学习如何度量样本之间的相似性或差异性。这种损失函数通常在对比学习任务中使用，其中目标是确保正样本对（相似样本）之间的距离小于负样本对（不相似样本）之间的距离，同时还考虑到了一个预定义的边距（margin），这有助于将相似性和差异性信息嵌入到学习的嵌入空间中。\n",
    "\n",
    "min-batch, $x_i = 1 - cosine(a,b)$\n",
    "\n",
    "$\n",
    " J = loss(x_i,y) = \\begin{cases}\n",
    " x_i  &  y == 1\\\\\n",
    " max(0, margin - x_i) &  y == -1\n",
    " \\end{cases}\n",
    "$\n",
    "\n",
    "$ \n",
    " \\frac {\\partial J}{\\partial _i } = \\begin{cases}\n",
    " 1 & y == 1 \\\\\n",
    " 0 & y == -1 \\text{ and  }margin< x_i \\\\\n",
    " -1 & y== -1 \\text{ and  }margin> x_i \n",
    " \\end{cases}\n",
    "$   \n",
    " \n",
    "> torch.nn.HingeEmbeddingLoss(margin=1.0,  reduction='mean')\n",
    "\n",
    "应用场景：siamese net或者Triplet net，非线形Embedding，半监督学习，监测两个输入的相似性或者不相\n",
    "## 三元组损失 TripletMarginLoss\n",
    "\n",
    "三元组损失（TripletMarginLoss）是一种用于训练嵌入模型的损失函数，用于学习具有良好特征表示的嵌入空间。它鼓励使同一类别的样本在嵌入空间中更接近，而不同类别的样本在嵌入空间中更远离。\n",
    "\n",
    "<img src=\"./data/img/triplet_loss.png\" style=\"zoom:50%\" />\n",
    "\n",
    "TripletMarginLoss = max(d(a, p) - d(a, n) + margin, 0)   \n",
    "其中，d(a, p)表示锚样本a与正样本p之间的距离，d(a, n)表示锚样本a与负样本n之间的距离，margin是边际参数。\n",
    "\n",
    ">torch.nn.TripletMarginLoss(margin=1.0, p=2.0, eps=1e-06, swap=False, reduction='mean')\n",
    "\n",
    "$d(x, y) = ||x-y||_p$\n",
    "\n",
    "## cosine 损失 CosineEmbeddingLoss\n",
    "余弦损失函数，余弦函数常常用于评估两个向量的相似性，两个向量的余弦值越高，则相似性越高。\n",
    "\n",
    "$\n",
    " loss(x_1, x_2) = \\begin{cases}\n",
    "1 - \\cos(x_1, x_2) & {y == 1}   \\\\\n",
    "max(0, \\cos(x_1, x_2) - margin) & {y == -1}\n",
    "\\end{cases}\n",
    "$\n",
    ">torch.nn.CosineEmbeddingLoss(margin=0.0, reduction='mean')\n",
    "\n",
    "应用场景：非线形Embedding，半监督学习，监测两个输入的相似性或者不相似性\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3db4779a-e2bb-413f-ac9d-07f62d24dff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100])\n",
      "0.4938560426235199\n",
      "tensor([0.0000, 1.0821, 0.0000, 1.0337, 1.0798, 0.0000, 1.0582, 0.0000, 0.8795,\n",
      "        0.0000, 1.1377, 0.0000, 0.9727, 1.0088, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.0000, 0.9941, 1.0539, 0.0000, 0.0000, 0.0000, 1.1907, 0.9647, 0.8875,\n",
      "        0.8585, 0.9471, 0.0000, 0.0000, 0.9677, 0.0000, 0.0000, 0.0000, 0.8393,\n",
      "        0.0000, 0.9900, 1.1510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.9491, 0.9202, 0.0000, 0.9338, 1.0044, 0.0000, 1.1716, 1.0480, 0.8654,\n",
      "        0.8302, 0.0000, 0.8969, 0.0000, 0.0000, 1.0293, 0.0000, 1.1107, 0.8257,\n",
      "        0.9162, 1.0796, 1.0330, 0.0000, 0.9933, 0.0000, 0.0000, 1.0066, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.9410, 0.8609, 1.0060, 0.0000, 0.8454, 0.0000,\n",
      "        1.0362, 0.0000, 1.0253, 1.0560, 1.0759, 0.9888, 0.0000, 1.0147, 0.8566,\n",
      "        0.9453, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9874, 0.0000, 0.0000,\n",
      "        1.0352], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "loss = nn.MarginRankingLoss()\n",
    "input1 = torch.randn(3, requires_grad=True)\n",
    "input2 = torch.randn(3, requires_grad=True)\n",
    "target = torch.randn(3).sign()\n",
    "output = loss(input1, input2, target)\n",
    "output.backward()\n",
    "\n",
    "torch.manual_seed(20)\n",
    "hinge_loss = nn.HingeEmbeddingLoss(margin=0.2)\n",
    "a = torch.randn(100, 128, requires_grad=True)\n",
    "b = torch.randn(100, 128, requires_grad=True)\n",
    "x = 1 - torch.cosine_similarity(a, b)\n",
    "# 定义a与b之间的距离为x\n",
    "print(x.size())\n",
    "y = 2 * torch.empty(100).random_(2) - 1\n",
    "output = hinge_loss(x, y)\n",
    "print(output.item())\n",
    "\n",
    "hinge_loss = nn.HingeEmbeddingLoss(margin=0.2, reduction=\"none\")\n",
    "output = hinge_loss(x, y)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc504cae-f227-4195-88be-164bc034ec73",
   "metadata": {},
   "source": [
    "## 多标签分类损失 MultiLabelMarginLoss\n",
    "MultiLabelMarginLoss（多标签边际损失）是一种用于多标签分类任务的损失函数。它适用于同时处理多个标签，并鼓励模型在每个标签上的预测与真实标签之间有较大的差异。\n",
    "\n",
    "$对于包含N个样本的batch数据 D(x ,y)，x为神经网络的输出，y是真实的类别，第n个样本的损失值l_n 计算如下：$   \n",
    "$l_n = \\frac {1}{C}\\sum_{j \\in y_n} \\sum_{i \\notin y_n} max(0, 1- x_n[j] + x_n[i])$\n",
    "\n",
    "$其中，每个样本对应的标签数量不同，只考虑y_{n}中数值-1之前的连续标签（下标）。 若某个样本对应的y_{n}=[2,3,-1,0]，表示总的标签有四个，而2和3标签属于该样本，0和1标签不属于该样本。y_{n}=[2,3,-1,0] 与y_{n}=[3,2,-1,0]两种表示相同。$\n",
    "\n",
    "torch.nn.MultiLabelMarginLoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75a8cc20-dfa1-47b8-830d-4514aaf637b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4])\n",
      "torch.Size([1, 4])\n",
      "0.8500000238418579\n",
      "0.8500000000000001\n",
      "0.7749999761581421\n",
      "0.7749999999999999\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "loss = nn.MultiLabelMarginLoss()\n",
    "x = torch.FloatTensor([[0.1, 0.2, 0.4, 0.8]])\n",
    "y = torch.LongTensor([[3, 0, -1, 1]])\n",
    "# j ∈ [3, 0],  i ∈ [1,2]\n",
    "print(x.size())\n",
    "print(y.size())\n",
    "\n",
    "loss_val = loss(x, y)\n",
    "print(loss_val.item())\n",
    "# 验证\n",
    "print(0.25 * ((1 - (0.8 - 0.2)) + (1 - (0.8 - 0.4)) + (1 - (0.1 - 0.2)) + (1 - (0.1 - 0.4))))\n",
    "\n",
    "y = torch.LongTensor([[3, 0, 1, -1]])\n",
    "# j ∈ [3, 0, 1],  i ∈ [2]\n",
    "loss_val = loss(x, y)\n",
    "print(loss_val.item())\n",
    "# 验证\n",
    "print(0.25 * ((1 - (0.8 - 0.4)) + (1 - (0.1 - 0.4)) + (1 - (0.2 - 0.4))))\n",
    "\n",
    "y = torch.LongTensor([[3, 0, 2, 1]])\n",
    "loss_val = loss(x, y)\n",
    "print(loss_val.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a12c96-7026-47bd-8faf-4614aa9661b6",
   "metadata": {},
   "source": [
    "## MultiMarginLoss\n",
    "多分类合页损失函数（hinge loss），对于一个样本不是考虑样本输出与真实类别之间的误差，而是考虑对应真实类别与其他类别之间的误差\n",
    "\n",
    "$对于包含N个样本的batch数据 D(x, y)，x为神经网络的输出，y是真实的类别标签，假设类别数为C, 0 \\leq y_{n} \\leq C-1。$\n",
    "\n",
    "$l_{n}=\\frac1{C}{ \\sum_{i=0 \\&i \\neq y_{n}}^{C-1} \\max (0, \\operatorname{margin}-x_{n}[y_{n}]+x_{n}[i])^{p}}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9067f5cb-74e5-4ef0-bb2a-cfc774902d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "torch.Size([2])\n",
      "tensor([0.3250, 0.3250])\n",
      "0.6499999761581421\n",
      "0.32499998807907104\n",
      "0.32499999999999996\n"
     ]
    }
   ],
   "source": [
    "x = torch.FloatTensor([[0.1, 0.2, 0.4, 0.8], [0.1, 0.2, 0.4, 0.8]])\n",
    "print(x.size())\n",
    "y = torch.LongTensor([3, 3])\n",
    "print(y.size())\n",
    "\n",
    "loss = nn.MultiMarginLoss(reduction=\"none\")\n",
    "loss_val = loss(x, y)\n",
    "print(loss_val)\n",
    "\n",
    "loss = nn.MultiMarginLoss(reduction=\"sum\")\n",
    "loss_val = loss(x, y)\n",
    "print(loss_val.item())\n",
    "print(loss_val.item() / x.size(0))\n",
    "#验证\n",
    "print(1 / 2 * 1 / 4 * ((1 - 0.8 + 0.1) + (1 - 0.8 + 0.2) + (1 - 0.8 + 0.4) +\n",
    "                       (1 - 0.8 + 0.1) + (1 - 0.8 + 0.2) + (1 - 0.8 + 0.4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec605d6-5543-4438-b667-e2255432fe8a",
   "metadata": {},
   "source": [
    "## 2分类的logistic损失 SoftMarginLoss\n",
    "\n",
    "SoftMarginLoss基于逻辑斯蒂回归（Logistic Regression）的概念，它使用了Sigmoid函数将预测输出映射到0到1之间的概率值，以表示样本属于正类的可能性。\n",
    "\n",
    "SoftMarginLoss的优点是在计算损失时，将模型输出通过Sigmoid函数转换为概率值，并将其与真实标签进行比较。当模型对正样本的预测概率较低或对负样本的预测概率较高时，SoftMarginLoss会给予较高的损失，促使模型更好地拟合数据。\n",
    "\n",
    "$loss = \\log(1 + e^{-y * \\hat y}), \\hat y = \\sigma (x) = \\frac {e^{\\hat x}}{ 1 + e^{\\hat x}}$\n",
    "\n",
    "$loss = \\frac {\\sum_i (\\log (1 + e ^{-y[i]*x[i]}))}{x.nelement}$   \n",
    "\n",
    "torch.nn.SoftMarginLoss(reduction='mean')\n",
    "\n",
    "## 多标签 one-versus-all 损失 MultiLabelSoftMarginLoss\n",
    "\n",
    "$ J = loss = -\\sum_i (y_i \\log \\sigma(\\hat y_i) + (1 - y_i) \\log (1 - \\sigma(\\hat y_i)))$\n",
    "\n",
    "$ Z = \\sigma(\\hat y) = \\frac {e^{\\hat y}}{ 1 + e^{\\hat y}},  \\frac {\\partial Z}{\\partial \\hat y} = Z(1-Z)$    \n",
    "$\\frac {\\partial J}{\\partial \\hat y} = \\frac {\\partial J}{\\partial Z} \\frac {\\partial Z}{\\partial \\hat y} = -(\\frac {y}{Z} + (1-y)\\frac {-1}{1-Z}) * Z(1-Z) = Z - Y$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bc9e541-22c7-40a0-b8ed-f1c8320cc268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "torch.Size([2, 4])\n",
      "tensor([[0.6444, 0.7981, 0.5130, 0.3711],\n",
      "        [0.6444, 0.7981, 0.5130, 0.3711]])\n",
      "4.653302192687988\n",
      "0.5816627740859985\n",
      "0.5816627740859985\n",
      "0.5816628606614725\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def validate_SoftMarginLoss(input, target):\n",
    "    val = 0\n",
    "    for li_x, li_y in zip(input, target):\n",
    "        for x, y in zip(li_x, li_y):\n",
    "            loss_val = math.log(1 + math.exp(- y * x), math.e)\n",
    "            val += loss_val\n",
    "    return val / input.nelement()\n",
    "\n",
    "    \n",
    "x = torch.FloatTensor([[0.1, 0.2, 0.4, 0.8], [0.1, 0.2, 0.4, 0.8]])\n",
    "print(x.size())\n",
    "y = torch.FloatTensor([[1, -1, 1, 1], [1, -1, 1, 1]])\n",
    "print(y.size())\n",
    "\n",
    "loss = nn.SoftMarginLoss(reduction=\"none\")\n",
    "loss_val = loss(x, y)\n",
    "print(loss_val)\n",
    "\n",
    "loss = nn.SoftMarginLoss(reduction=\"sum\")\n",
    "loss_val = loss(x, y)\n",
    "print(loss_val.item())\n",
    "print(loss_val.item() / x.nelement())\n",
    "\n",
    "loss = nn.SoftMarginLoss(reduction=\"mean\")\n",
    "loss_val = loss(x, y)\n",
    "print(loss_val.item())\n",
    "\n",
    "valid_loss_val = validate_SoftMarginLoss(x, y)\n",
    "print(valid_loss_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b9e049-ea31-4ed2-b3e6-e9f4f65caf4f",
   "metadata": {},
   "source": [
    "### 连接时序分类损失 CTCLoss\n",
    "\n",
    "\n",
    "连接时序分类损失（Connectionist Temporal Classification Loss，CTCLoss）是一种用于训练时序分类模型（如语音识别、文本识别等）的损失函数。它解决了时序数据对齐与标签对齐之间的问题，允许模型在训练过程中学习对不确定的对齐进行建模。\n",
    "\n",
    "CTCLoss的计算方式基于前向-后向算法（Forward-Backward Algorithm）和动态规划的思想，用于计算模型预测序列和真实标签序列之间的对齐成本。\n",
    "\n",
    "CTCLoss的主要步骤如下：\n",
    "\n",
    " * 预测：模型生成一个输出序列，通常使用Softmax函数将输出映射到概率分布。\n",
    " * 对齐：使用对齐算法（如束搜索、动态规划等）将预测序列与真实标签序列对齐，考虑到不同长度和对齐的可能性。\n",
    " * 成本计算：计算对齐序列的成本，即模型预测序列与真实标签序列之间的差异。\n",
    " * 损失计算：将成本转化为损失值，通过最小化损失值来调整模型的参数。\n",
    "CTCLoss的优点是它不需要对齐预测序列和标签序列，而是通过计算所有可能的对齐方式的平均成本来训练模型。这使得模型能够学习到更好的对齐模式，并对不完全对齐的数据具有鲁棒性。\n",
    "\n",
    "通过最小化CTCLoss来调整模型的参数，可以使模型在时序分类任务中更好地学习到数据的时序特征，并提高分类准确性。CTCLoss在语音识别、文本识别等领域得到了广泛的应用。\n",
    "\n",
    "CTC连接时序分类损失，可以对没有对齐的数据进行自动对齐，主要用在没有事先对齐的序列化数据训练上。比如语音识别、ocr识别等等。\n",
    "\n",
    "> torch.nn.CTCLoss(blank=0, reduction='mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf1aa60-0f03-4ffd-9b88-24a7145fab21",
   "metadata": {},
   "source": [
    "### 负对数似然损失 NLLLoss (Negative Log-Likelihood Loss)\n",
    "负对数似然损失（Negative Log-Likelihood Loss，NLLLoss）是一种常用的损失函数，用于多类别分类任务中的概率建模。它基于最大似然估计的原理，鼓励模型预测正确类别的概率尽可能高。\n",
    "\n",
    "$ \\hat y_i = softmax(x_i) =  \\frac {e^{x_i}}{\\sum_c e^{x_c}}$   \n",
    "$ logSoftmax(x_i) = \\log \\frac {e^{x_i}}{\\sum_c e^{x_c}} = \\log \\hat y_i$   \n",
    "$NLLLoss(\\hat y) = -\\sum_c y \\hat y$\n",
    "\n",
    "$CrossEntropyLoss (x,y)= -\\sum_c y\\log \\hat y = -\\sum_c y* logSoftmax(x) = NLLLoss(logSoftmax(x))$\n",
    "\n",
    ">torch.nn.NLLLoss(weight=None, ignore_index=-100,  reduction='mean')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3439279-3483-4c05-9317-7aaaed666d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "torch.Size([4])\n",
      "tensor([[-0.9976, -0.8976, -1.4976],\n",
      "        [-0.9976, -0.8976, -1.4976],\n",
      "        [-0.9976, -0.8976, -1.4976],\n",
      "        [-0.9976, -0.8976, -1.4976]])\n",
      "0.9475762844085693\n",
      "0.9475762844085693\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 多分类\n",
    "m = torch.nn.LogSoftmax(dim=1)\n",
    "loss_nll_fct = nn.NLLLoss(reduction=\"mean\")\n",
    "loss_ce_fct = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "input_src = torch.Tensor([[0.8, 0.9, 0.3], [0.8, 0.9, 0.3], [0.8, 0.9, 0.3], [0.8, 0.9, 0.3]])\n",
    "target = torch.Tensor([1, 1, 0, 0]).long()\n",
    "# 4个样本，3分类\n",
    "print(input_src.size())\n",
    "print(target.size())\n",
    "output = m(input_src)\n",
    "print(output)\n",
    "loss_nll = loss_nll_fct(output, target)\n",
    "print(loss_nll.item())\n",
    "# 验证是否一致\n",
    "loss_ce = loss_ce_fct(input_src, target)\n",
    "print(loss_ce.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88d96c7-b772-4a04-a9ab-609b66051999",
   "metadata": {},
   "source": [
    "### PoissonNLLLoss\n",
    "PoissonNLLLoss是一种用于训练计数数据模型的损失函数，通常用于处理具有Poisson分布特性的数据。它衡量模型的预测与真实计数值之间的差异，并鼓励模型学习生成接近真实计数分布的预测结果。\n",
    "\n",
    "PoissonNLLLoss的计算方式如下：\n",
    "$PoissonNLLLoss = e^{\\hat y} - y * \\hat y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54050d69-5130-442f-b9b8-56cf720d3b06",
   "metadata": {},
   "source": [
    "### NLLLoss2d\n",
    "\"NLLLoss2d\"并不是标准的损失函数名称，可能是一个自定义的损失函数或者特定库中的命名。一般情况下，NLLLoss（负对数似然损失）用于多类别分类任务，而\"NLLLoss2d\"可能是指在特定情况下应用NLLLoss的二维版本。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df9b9f1-4ac7-4167-ba84-b9dc38984660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
