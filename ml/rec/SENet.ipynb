{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee12abdb-d2c5-454c-806b-6f56d3d24564",
   "metadata": {},
   "source": [
    " />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b7ccc7-0a31-4a1c-8162-67755c1fc4e9",
   "metadata": {},
   "source": [
    "## SENet\n",
    "\n",
    "SENet的全称是Squeeze-and-Excitation Networks，中文可以翻译为压缩和激励网络\n",
    "\n",
    "SENet是ImageNet 2017（ImageNet收官赛）的冠军模型，和ResNet的出现类似，都在很大程度上减小了之前模型的错误率（具体见附录），并且复杂度低，新增参数和计算量小。\n",
    "\n",
    "1. Squeeze部分。即为压缩部分，原始feature map的维度为H*W*C，其中H是高度（Height），W是宽度（width），C是通道数（channel）。Squeeze做的事情是把H*W*C压缩为1*1*C，相当于把H*W压缩成一维了，实际中一般是用global average pooling实现的。H*W压缩成一维后，相当于这一维参数获得了之前H*W全局的视野，感受区域更广。\n",
    "\n",
    "2. Excitation部分。得到Squeeze的1*1*C的表示后，加入一个FC全连接层（Fully Connected），对每个通道的重要性进行预测，得到不同channel的重要性大小后再作用（激励）到之前的feature map的对应channel上，再进行后续操作。\n",
    "\n",
    "3. Scale操作：即Reweight ，将 Excitation 的输出的权重看做是进行过特征选择后的每个特征通道的重要性，然后通过乘法逐通道加权到先前的特征上，完成在通道维度上的对原始特征的重标定。\n",
    "\n",
    "<img src=\"../data/img/senet.png\" style=\"zoom:50%\"/>\n",
    "\n",
    "SENet 的核心思想在于通过网络根据 loss 去学习特征权重，使得有效的 feature map 权重大，无效或效果小的 feature map 权重小的方式训练模型达到更好的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b86a04-5651-4b10-aef1-63aeeadfdf3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
